{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `selector` not found.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "stream_urls_dict = {}\n",
    "\n",
    "# add https://livestormchasing.com/chasers/jason.cooley to the dictionary\n",
    "stream_urls_dict['Jason Cooley'] = 'https://livestormchasing.com/chasers/jason.cooley'\n",
    "# add https://livestormchasing.com/chasers/steve.wooten to the dictionary\n",
    "stream_urls_dict['Steve Wooten'] = 'https://livestormchasing.com/chasers/steve.wooten'\n",
    "# https://livestormchasing.com/chasers/brett.adair\n",
    "stream_urls_dict['Brett Adair'] = 'https://livestormchasing.com/chasers/brett.adair'\n",
    "# Michael Craddock\n",
    "stream_urls_dict['Michael Craddock'] = 'https://livestormchasing.com/chasers/michael.craddock'\n",
    "# https://livestormchasing.com/chasers/ryan.mccarthy\n",
    "stream_urls_dict['Ryan McCarthy'] = 'https://livestormchasing.com/chasers/ryan.mccarthy'\n",
    "# David Gaede\n",
    "stream_urls_dict['David Gaede'] = 'https://livestormchasing.com/chasers/david.gaede'\n",
    "# https://livestormchasing.com/chasers/brad.arnold\n",
    "stream_urls_dict['Brad Arnold'] = 'https://livestormchasing.com/chasers/brad.arnold'\n",
    "# James McMullin\n",
    "stream_urls_dict['James McMullin'] = 'https://livestormchasing.com/chasers/james.mcmullin'\n",
    "\n",
    "How can I extract the names in the elements at this css selector?\n",
    "#app > div > div.absolute.w-full.bg-grey-darker.text-white.max-w-25rem.flex-col.overflow-hidden.z-50.pin-b.ml-4.mb-4.rounded-lg > div.overflow-y-auto > div:nth-child(1) > div.w-full.h-auto > div > div:nth-child(7) > div > div.w-full.mt-3\n",
    "\n",
    "def get_streams():\n",
    "    url = 'https://livestormchasing.com/map'\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    # find all the div id \"stream\" elements\n",
    "    streams = soup.find_all('div', id='stream')\n",
    "    # create a list of the stream names\n",
    "    stream_names = [stream.find('h3').text for stream in streams]\n",
    "    # create a list of the stream urls\n",
    "    stream_urls = [stream.find('iframe')['src'] for stream in streams]\n",
    "    # create a list of the stream descriptions\n",
    "    stream_descriptions = [stream.find('p').text for stream in streams]\n",
    "    # create a list of the stream locations\n",
    "    stream_locations = [stream.find('h4').text for stream in streams]\n",
    "    # create a list of the stream viewers\n",
    "    stream_viewers = [stream.find('span', class_='viewers').text for stream in streams]\n",
    "    # create a list of the stream tags\n",
    "    stream_tags = [stream.find('span', class_='tags').text for stream in streams]\n",
    "    # create a list of the stream thumbnails\n",
    "    stream_thumbnails = [stream.find('img')['src'] for stream in streams]\n",
    "    # create a list of the stream start times\n",
    "    stream_start_times = [stream.find('span', class_='start-time').text for stream in streams]\n",
    "    # create a list of the stream end times\n",
    "    stream_end_times = [stream.find('span', class_='end-time').text for stream in streams]\n",
    "    # create a list of the stream durations\n",
    "    stream_durations = [stream.find('span', class_='duration').text for stream in streams]\n",
    "    # create a list of the stream categories\n",
    "    stream_categories = [stream.find('span', class_='category').text for stream in streams]\n",
    "    # create a list of the stream languages\n",
    "    stream_languages = [stream.find('span', class_='language').text for stream in streams]\n",
    "    # create a list of the stream countries\n",
    "    stream_countries = [stream.find('span', class_='country').text for stream in streams]\n",
    "    # create a list of the stream states\n",
    "    stream_states = [stream.find('span', class_='state').text for stream in streams]\n",
    "    # create a list of the stream cities\n",
    "    stream_cities = [stream.find('span', class_='city').text for stream in streams]\n",
    "    # create a list of the stream latitudes\n",
    "    stream_latitudes = [stream.find('span', class_='latitude').text for stream in streams]\n",
    "    # create a list of the stream longitudes\n",
    "    stream_longitudes = [stream.find('span', class_='longitude').text for stream in streams]\n",
    "\n",
    "    return streams\n",
    "\n",
    "streams = get_streams()\n",
    "print(streams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "stream_urls_dict = {}\n",
    "\n",
    "# add https://livestormchasing.com/chasers/jason.cooley to the dictionary\n",
    "stream_urls_dict['Jason Cooley'] = 'https://livestormchasing.com/chasers/jason.cooley'\n",
    "# add https://livestormchasing.com/chasers/steve.wooten to the dictionary\n",
    "stream_urls_dict['Steve Wooten'] = 'https://livestormchasing.com/chasers/steve.wooten'\n",
    "# https://livestormchasing.com/chasers/brett.adair\n",
    "stream_urls_dict['Brett Adair'] = 'https://livestormchasing.com/chasers/brett.adair'\n",
    "# Michael Craddock\n",
    "stream_urls_dict['Michael Craddock'] = 'https://livestormchasing.com/chasers/michael.craddock'\n",
    "# https://livestormchasing.com/chasers/ryan.mccarthy\n",
    "stream_urls_dict['Ryan McCarthy'] = 'https://livestormchasing.com/chasers/ryan.mccarthy'\n",
    "# https://livestormchasing.com/chasers/brad.arnold\n",
    "stream_urls_dict['Brad Arnold'] = 'https://livestormchasing.com/chasers/brad.arnold'\n",
    "# James McMullin\n",
    "stream_urls_dict['James McMullin'] = 'https://livestormchasing.com/chasers/james.mcmullin'\n",
    "# Eric Tole\n",
    "stream_urls_dict['Eric Tole'] = 'https://livestormchasing.com/chasers/eric.tole'\n",
    "# Joshua Myers\n",
    "stream_urls_dict['Joshua Myers'] = 'https://livestormchasing.com/chasers/joshua.myers'\n",
    "# Kory Poggenpohl\n",
    "stream_urls_dict['Kory Poggenpohl'] = 'https://livestormchasing.com/chasers/kory.poggenpohl'\n",
    "# Ryan Cartee\n",
    "stream_urls_dict['Ryan Cartee'] = 'https://livestormchasing.com/chasers/ryan.cartee'\n",
    "# Jason Cooley\n",
    "stream_urls_dict['Jason Cooley'] = 'https://livestormchasing.com/chasers/jason.cooley'\n",
    "# Brett Adair\n",
    "stream_urls_dict['Brett Adair'] = 'https://livestormchasing.com/chasers/brett.adair'\n",
    "# Steve Wooten\n",
    "stream_urls_dict['Steve Wooten'] = 'https://livestormchasing.com/chasers/steve.wooten'\n",
    "# Colby Ward\n",
    "stream_urls_dict['Colby Ward'] = 'https://livestormchasing.com/chasers/colby.ward'\n",
    "# Michael Craddock\n",
    "stream_urls_dict['Michael Craddock'] = 'https://livestormchasing.com/chasers/michael.craddock'\n",
    "# Ryan McCarthy\n",
    "stream_urls_dict['Ryan McCarthy'] = 'https://livestormchasing.com/chasers/ryan.mccarthy'\n",
    "# David Gaede\n",
    "stream_urls_dict['David Gaede'] = 'https://livestormchasing.com/chasers/david.gaede'\n",
    "# Brad Arnold\n",
    "stream_urls_dict['Brad Arnold'] = 'https://livestormchasing.com/chasers/brad.arnold'\n",
    "# James McMullin\n",
    "stream_urls_dict['James McMullin'] = 'https://livestormchasing.com/chasers/james.mcmullin'\n",
    "\n",
    "# the css selector on the subpages for the video file is \"#stream > div > div.container > video\"\n",
    "\n",
    "\n",
    "# Get the streams from the stream urls in the urls dictionary and create a panel of videos from the streams using the stream urls and stream names as the keys and values respectively in the dictionary.\n",
    "def get_streams(streams_urls_dict):\n",
    "    streams = []\n",
    "    videos = []\n",
    "    for stream_name, stream_url in stream_urls_dict.items():\n",
    "        try:\n",
    "            # get the stream\n",
    "            stream = requests.get(stream_url)\n",
    "            # create a BeautifulSoup object\n",
    "            #     soup = BeautifulSoup(stream.content, 'html.parser')\n",
    "            #     # get the stream\n",
    "            #     stream = soup.find('div', class_='stream')\n",
    "            #     # get the stream name\n",
    "            #     stream_name = stream.find('h3').text\n",
    "            #     # get the stream url\n",
    "            #     stream_url = stream.find('iframe')['src']\n",
    "            #     # get the stream description\n",
    "            #     stream_description = stream.find('p').text\n",
    "            #     # get the stream location\n",
    "            #     stream_location = stream.find('h4').text\n",
    "            #     # get the stream viewers\n",
    "            #     stream_viewers = stream.find('span', class_='viewers').text\n",
    "            #     # get the stream tags\n",
    "            #     stream_tags = stream.find('span', class_='tags').text\n",
    "            #     # get the stream thumbnail\n",
    "            #     stream_thumbnail = stream.find('img')['src']\n",
    "            #     # get the stream start time\n",
    "            #     stream_start_time = stream.find('span', class_='start-time').text\n",
    "            #     # get the stream end time\n",
    "            #     stream_end_time = stream.find('span', class_='end-time').text\n",
    "            #     # get the stream duration\n",
    "            #     stream_duration = stream.find('span', class_='duration').text\n",
    "            #     # get the stream category\n",
    "            #     stream_category = stream.find('span', class_='category').text\n",
    "            #     # get the stream language\n",
    "            #     stream_language = stream.find('span', class_='language').text\n",
    "            #     # get the stream country\n",
    "            #     stream_country = stream.find('span', class_='country').text\n",
    "            #     # get the stream state\n",
    "            #     stream_state = stream.find('span', class_='state').text\n",
    "            #     # get the stream city\n",
    "            #     stream_city = stream.find('span', class_='city').text\n",
    "            #     # get the stream latitude\n",
    "            #     stream_latitude = stream.find('span', class_='latitude').text\n",
    "            #     # get the stream longitude\n",
    "            #     stream_longitude = stream.find('span', class_='longitude').text\n",
    "            #     # create a dictionary of the stream information\n",
    "            #     stream_dict = {\n",
    "            #         'stream_name': stream_name,\n",
    "            #         'stream_url': stream_url,\n",
    "            #         'stream_description': stream_description,\n",
    "            #         'stream_location': stream_location,\n",
    "            #         'stream_viewers': stream_viewers,\n",
    "            #         'stream_tags': stream_tags,\n",
    "            #         'stream_thumbnail': stream_thumbnail,\n",
    "            #         'stream_start_time': stream_start_time,\n",
    "            #         'stream_end_time': stream_end_time,\n",
    "            #         'stream_duration': stream_duration,\n",
    "            #         'stream_category': stream_category,\n",
    "            #         'stream_language': stream_language,\n",
    "            #         'stream_country': stream_country,\n",
    "            #         'stream_state': stream_state,\n",
    "            #         'stream_city': stream_city,\n",
    "            #         'stream_latitude': stream_latitude,\n",
    "            #         'stream_longitude': stream_longitude\n",
    "            #     }\n",
    "            #     # append the stream dictionary to the streams list\n",
    "            #     streams.append(stream_dict)\n",
    "            # except Exception as e:\n",
    "            #     print(\"Error getting stream: \", e)\n",
    "        \n",
    "            # get the video on the page\n",
    "            soup = BeautifulSoup(stream.content, 'html.parser')\n",
    "            try:\n",
    "                video = soup.find('video')\n",
    "                # get the video source\n",
    "                video_source = video.find('source')['src']\n",
    "                # get the video type\n",
    "                video_type = video.find('source')['type']\n",
    "                # get the video width\n",
    "                video_width = video['width']\n",
    "                # get the video height\n",
    "                video_height = video['height']\n",
    "                # get the video poster\n",
    "                video_poster = video['poster']\n",
    "                # get the video preload\n",
    "                video_preload = video['preload']\n",
    "                # get the video controls\n",
    "                video_controls = video['controls']\n",
    "                # create a dictionary of the video information\n",
    "                video_dict = {\n",
    "                    'video_source': video_source,\n",
    "                    'video_type': video_type,\n",
    "                    'video_width': video_width,\n",
    "                    'video_height': video_height,\n",
    "                    'video_poster': video_poster,\n",
    "                    'video_preload': video_preload,\n",
    "                    'video_controls': video_controls\n",
    "                }\n",
    "                # append the video dictionary to the videos list\n",
    "                videos.append(video_dict)\n",
    "            except Exception as e:\n",
    "                print(\"Error getting video: \", e)\n",
    "        except Exception as e:\n",
    "            print(\"Error getting stream: \", e)\n",
    "    return streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install panel -q\n",
    "!pip install jupyter_bokeh -q\n",
    "import panel as pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a panel of videos from the streams\n",
    "def create_panel(streams):\n",
    "    # create a panel of videos from the streams\n",
    "    panel = pn.Column()\n",
    "    # iterate through the streams\n",
    "    for stream in streams:\n",
    "        # create a panel of the stream information\n",
    "        stream_panel = pn.Column(\n",
    "            pn.pane.HTML(\n",
    "                f\"\"\"\n",
    "                <h3>{stream['stream_name']}</h3>\n",
    "                <p>{stream['stream_description']}</p>\n",
    "                <p>{stream['stream_location']}</p>\n",
    "                <p>{stream['stream_viewers']}</p>\n",
    "                <p>{stream['stream_tags']}</p>\n",
    "                <p>{stream['stream_start_time']}</p>\n",
    "                <p>{stream['stream_end_time']}</p>\n",
    "                <p>{stream['stream_duration']}</p>\n",
    "                <p>{stream['stream_category']}</p>\n",
    "                <p>{stream['stream_language']}</p>\n",
    "                <p>{stream['stream_country']}</p>\n",
    "                <p>{stream['stream_state']}</p>\n",
    "                <p>{stream['stream_city']}</p>\n",
    "                <p>{stream['stream_latitude']}</p>\n",
    "                <p>{stream['stream_longitude']}</p>\n",
    "                \"\"\"\n",
    "            ),\n",
    "            pn.pane.HTML(\n",
    "                f\"\"\"\n",
    "                <iframe src=\"{stream['stream_url']}\" width=\"560\" height=\"315\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen></iframe>\n",
    "                \"\"\"\n",
    "            )\n",
    "        )\n",
    "        # append the stream panel to the panel\n",
    "        panel.append(stream_panel)\n",
    "    return panel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting video:  'NoneType' object has no attribute 'find'\n",
      "Error getting video:  'NoneType' object has no attribute 'find'\n",
      "Error getting video:  'NoneType' object has no attribute 'find'\n",
      "Error getting video:  'NoneType' object has no attribute 'find'\n",
      "Error getting video:  'NoneType' object has no attribute 'find'\n",
      "Error getting video:  'NoneType' object has no attribute 'find'\n",
      "Error getting video:  'NoneType' object has no attribute 'find'\n",
      "Error getting video:  'NoneType' object has no attribute 'find'\n",
      "Error getting video:  'NoneType' object has no attribute 'find'\n",
      "Error getting video:  'NoneType' object has no attribute 'find'\n",
      "Error getting video:  'NoneType' object has no attribute 'find'\n",
      "Error getting video:  'NoneType' object has no attribute 'find'\n",
      "Error getting video:  'NoneType' object has no attribute 'find'\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m panel_result\u001b[39m.\u001b[39mservable() \u001b[39m# serve the panel\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# show one of the streams\u001b[39;00m\n\u001b[1;32m      5\u001b[0m pn\u001b[39m.\u001b[39mpane\u001b[39m.\u001b[39mHTML(\n\u001b[1;32m      6\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[39m    <iframe src=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mstreams_result[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mstream_url\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m width=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m560\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m height=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m315\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m frameborder=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m allow=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mautoplay; fullscreen\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m allowfullscreen></iframe>\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "streams_result = get_streams(stream_urls_dict) # get the streams\n",
    "panel_result = create_panel(streams_result) # create a panel of videos from the streams\n",
    "panel_result.servable() # serve the panel\n",
    "# show one of the streams\n",
    "pn.pane.HTML(\n",
    "    f\"\"\"\n",
    "    <iframe src=\"{streams_result[0]['stream_url']}\" width=\"560\" height=\"315\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen></iframe>\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'gridstack': {'exports': 'GridStack'}}});\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 2;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.2/dist/bundled/gridstack/gridstack@4.2.5/dist/gridstack-h5.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.2/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\", \"https://unpkg.com/@holoviz/panel@0.14.2/dist/panel.min.js\"];\n  var js_modules = [];\n  var css_urls = [\"https://cdn.holoviz.org/panel/0.14.2/dist/css/debugger.css\", \"https://cdn.holoviz.org/panel/0.14.2/dist/css/alerts.css\", \"https://cdn.holoviz.org/panel/0.14.2/dist/css/card.css\", \"https://cdn.holoviz.org/panel/0.14.2/dist/css/widgets.css\", \"https://cdn.holoviz.org/panel/0.14.2/dist/css/markdown.css\", \"https://cdn.holoviz.org/panel/0.14.2/dist/css/json.css\", \"https://cdn.holoviz.org/panel/0.14.2/dist/css/loading.css\", \"https://cdn.holoviz.org/panel/0.14.2/dist/css/dataframe.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\"\\n    .bk.pn-loading.arc:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n      background-size: auto calc(min(50%, 400px));\\n    }\\n    \");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, js_modules, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.bk-root, .bk-root .bk:before, .bk-root .bk:after {\n",
       "  font-family: var(--jp-ui-font-size1);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c23360c79924b669a008b153e6232d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'9547461d-b14b-4733-b087-7f22b04cc7b5': {'defs': …"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a panel of videos from the streams\n",
    "panel = create_panel(get_streams(stream_urls_dict))\n",
    "\n",
    "import panel as pn\n",
    "pn.extension() # enable the panel extension\n",
    "# create a dashboard\n",
    "dashboard = pn.Column(\n",
    "    '# Storm Chasing Streams',\n",
    "    panel\n",
    ")\n",
    "\n",
    "# show the dashboard\n",
    "dashboard.servable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://livestormchasing.com/chasers/brad.arnold\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "video_element = soup.find(\"video\", {\"data-html5-video\":\"\"})\n",
    "\n",
    "if video_element:\n",
    "    video_url = video_element.get(\"src\")\n",
    "else:\n",
    "    video_url = None\n",
    "\n",
    "\n",
    "print(video_url)\n",
    "\n",
    "with open(\"video.html\", \"w\") as f:\n",
    "    f.write(f\"\"\"\n",
    "    <html>\n",
    "    <body>\n",
    "    <iframe width=\"560\" height=\"315\" src=\"{video_url}\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Make a request to the webpage\n",
    "response = requests.get(\"https://livestormchasing.com/map\")\n",
    "\n",
    "# Parse the HTML content of the webpage\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all the elements with the class 'text-xl font-bold'\n",
    "elements = soup.find_all(class_='text-xl font-bold')\n",
    "\n",
    "# Extract the names from the elements\n",
    "names = [element.text for element in elements]\n",
    "\n",
    "print(names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groupme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28dd76f97a2595215b3511d9563b8125e93469ee739d17a6b25584482d270cb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
